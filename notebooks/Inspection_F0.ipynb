{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import librosa\n",
    "\n",
    "sys.path.insert(0, '/mnt/d/projects/bassline_extraction') \n",
    "\n",
    "import utilities as utils\n",
    "from plotting import *\n",
    "from transcription import *\n",
    "from signal_processing import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "## Directories\n",
    "\n",
    "**TO DO: aligned_beat_positions => progression_beat_positions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ouz_tracks.txt', 'r') as infile:\n",
    "    track_titles = infile.read().split('\\n')\n",
    "       \n",
    "_,_, bad_examples = next(os.walk('../data/bassline_extraction/beat_grid/bad_examples'))\n",
    "bad_examples = [title.split('.txt')[0] for title in bad_examples]\n",
    "       \n",
    "with open('../data/metadata/scales_frequencies.json','r') as infile:\n",
    "    scales = json.load(infile)\n",
    "\n",
    "with open('../data/metadata/TechHouse_track_dicts.json','r') as infile:\n",
    "    track_dicts = json.load(infile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def pYIN_F0(audio, fs, frame_length):\n",
    "\n",
    "    hop_length = int(frame_length/4) # 4 by default\n",
    "\n",
    "    F0, _, confidence = pyin(audio,\n",
    "                            sr=fs,\n",
    "                            frame_length=frame_length,\n",
    "                            hop_length=hop_length,\n",
    "                            fmin=31.0,\n",
    "                            fmax=130.0,\n",
    "                            fill_na=0.0)\n",
    "    \n",
    "    plot_confidence(title, confidence, save=True, plot_title='Confidence_pYIN')\n",
    "\n",
    "    time_axis = np.arange(len(F0)) * (hop_length/fs)\n",
    "\n",
    "    return (time_axis, F0)#, (time_axis, F0_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pYIN_F0(audio, fs, frame_length, threshold='none'): #, win_length, hop_length, threshold='none'):\n",
    "    \n",
    "    hop_length = int(frame_length/4) # 4 by default\n",
    "    \n",
    "    F0, _, confidence = pyin(audio,\n",
    "                            sr=fs,\n",
    "                            frame_length=frame_length,\n",
    "                            win_length=win_length,\n",
    "                            #hop_length=hop_length,\n",
    "                            #resolution=0.5,\n",
    "                            #boltzmann_parameter = 100,\n",
    "                            fmin=31.0,\n",
    "                            fmax=130.0,\n",
    "                            fill_na=0.0)\n",
    "\n",
    "    mean, std = np.mean(confidence), np.std(confidence)\n",
    "    \n",
    "    plot_confidence(title, confidence, save=True, plot_title='Confidence_pYIN')\n",
    "\n",
    "    if threshold == 'none':\n",
    "        threshold = 0\n",
    "    elif threshold == 'mean':\n",
    "        threshold = mean\n",
    "    elif threshold == 'mean_reduced':\n",
    "        threshold = mean - (std/2)\n",
    "    else:\n",
    "        assert threshold <= 1.0 and threshold > 0, 'Threshold must be inside (0, 1)'\n",
    "\n",
    "    F0_filtered = np.array(confidence_filter(F0, confidence, threshold))\n",
    "\n",
    "    time_axis = np.arange(len(F0)) * (hop_length/fs)\n",
    "\n",
    "    return (time_axis, F0), (time_axis, F0_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in track_titles:\n",
    "\n",
    "    try:\n",
    "\n",
    "        print('{}\\n'.format(title))\n",
    "        BPM = float(track_dicts[title]['BPM'])\n",
    "        beat_length = 60/BPM\n",
    "\n",
    "        if title in bad_examples:\n",
    "            with open(os.path.join('../data/bassline_extraction/beat_grid/bad_examples',title+'.txt'), 'r') as infile:\n",
    "                dpqb = float(infile.read())\n",
    "\n",
    "            #if dpqb > \n",
    "                #continue\n",
    "            print(\"Beat grid problematic! dpqb: {:.2f}%\\n{}\".format(dpqb,title))\n",
    "\n",
    "        notes, scale_frequencies = utils.get_track_scale(title, track_dicts, scales)\n",
    "\n",
    "        fs = 44100\n",
    "        chorus, bassline, _ = utils.load_audio(title) # read the chorus and the bassline\n",
    "\n",
    "        # spectrogram \n",
    "        beat_factor = 8\n",
    "        win_length = int((beat_length/beat_factor)*fs) \n",
    "        n_fft = 4096*8\n",
    "        hop_length = int(win_length/2) \n",
    "        assert win_length < n_fft, 'Window length must be greater than N_fft'\n",
    "\n",
    "        bassline_spectrogram = extract_dB_spectrogram(bassline, n_fft, win_length, hop_length)\n",
    "\n",
    "        # F0 estimation  \n",
    "        beat_factor = 4 # quarter 4, 1/8th 8...\n",
    "        frame_length = int((beat_length/beat_factor)*fs)\n",
    "        #win_length = int(frame_length/2)\n",
    "        #hop_length = int(frame_length/8)\n",
    "\n",
    "        F0_estimate, pitch_track = pYIN_F0(bassline, fs, frame_length, threshold=0.05)\n",
    "\n",
    "        plot_confidence_filtering_effect(title, bassline_spectrogram, fs, hop_length,\n",
    "                                         F0_estimate, pitch_track, save=True, plot_title='')\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        import sys\n",
    "        sys.exit()\n",
    "        pass \n",
    "    except:\n",
    "        print('error on {}'.format(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SÄ°ngle track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = track_titles[6]\n",
    "\n",
    "print('{}\\n'.format(title))\n",
    "BPM = float(track_dicts[title]['BPM'])\n",
    "beat_length = 60/BPM\n",
    "\n",
    "if title in bad_examples:\n",
    "    with open(os.path.join('../data/bassline_extraction/beat_grid/bad_examples',title+'.txt'), 'r') as infile:\n",
    "        dpqb = float(infile.read())\n",
    "\n",
    "    #if dpqb > \n",
    "        #continue\n",
    "    print(\"Beat grid problematic! dpqb: {:.2f}%\\n{}\".format(dpqb,title))\n",
    "\n",
    "notes, scale_frequencies = utils.get_track_scale(title, track_dicts, scales)\n",
    "\n",
    "fs = 44100\n",
    "chorus, bassline, _ = utils.load_audio(title) # read the chorus and the bassline\n",
    "\n",
    "# spectrogram \n",
    "beat_factor = 8\n",
    "win_length = int((beat_length/beat_factor)*fs) \n",
    "n_fft = 4096*8\n",
    "hop_length = int(win_length/2) \n",
    "assert win_length < n_fft, 'Window length must be greater than N_fft'\n",
    "\n",
    "bassline_spectrogram = extract_dB_spectrogram(bassline, n_fft, win_length, hop_length)\n",
    "\n",
    "# F0 estimation  \n",
    "beat_factor = 4 # quarter 4, 1/8th 8...\n",
    "frame_length = int((beat_length/beat_factor)*fs)\n",
    "#win_length = int(frame_length/2)\n",
    "#hop_length = int(frame_length/8)\n",
    "\n",
    "F0_estimate, pitch_track = pYIN_F0(bassline, fs, frame_length, threshold=0.05)\n",
    "\n",
    "plot_confidence_filtering_effect(title, bassline_spectrogram, fs, hop_length,\n",
    "                                 F0_estimate, pitch_track, save=True, plot_title='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crepe vs pYIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.random.randint(0, 200, 50):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        title = track_titles[i]\n",
    "        print('{}\\n'.format(title))\n",
    "        BPM = float(track_dicts[title]['BPM'])\n",
    "        beat_length = 60/BPM\n",
    "\n",
    "        if title in bad_examples:\n",
    "            with open(os.path.join('../data/bassline_extraction/beat_grid/bad_examples',title+'.txt'), 'r') as infile:\n",
    "                dpqb = float(infile.read())\n",
    "            print(\"Beat grid problematic! dpqb: {:.2f}%\\n{}\".format(dpqb,title))\n",
    "\n",
    "        notes, scale_frequencies = utils.get_track_scale(title, track_dicts, scales)\n",
    "\n",
    "        fs = 44100\n",
    "        chorus, bassline, unprocessed_bassline = utils.load_audio(title) # read the chorus and the bassline\n",
    "\n",
    "        beat_factor = 4\n",
    "        win_length = int((beat_length/beat_factor)*fs) \n",
    "\n",
    "        n_fft = 4096*8\n",
    "        #win_length = 4096*4\n",
    "\n",
    "        hop_length = int(win_length/2) \n",
    "        assert win_length < n_fft, 'Window length must be greater than N_fft'\n",
    "\n",
    "        #chorus_spectrogram = extract_dB_spectrogram(chorus, n_fft, win_length, hop_length)\n",
    "        bassline_spectrogram = extract_dB_spectrogram(bassline, n_fft, win_length, hop_length)\n",
    "\n",
    "\n",
    "        beat_factor = 8 \n",
    "        F0_estimates  = yin_crepe(title, bassline, fs, int((beat_length/beat_factor)*fs), save=True) \n",
    "\n",
    "        plot_algorithm_comparison_raw(title, bassline_spectrogram, fs, hop_length, F0_estimates, ['CREPE', 'pYIN'], save=True)\n",
    "        \n",
    "    except:\n",
    "        print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yin_crepe(title, bassline, fs, frame_length, save=False):\n",
    "        \n",
    "    time_axis, F0, confidence_crepe, _ = crepe_predict(bassline, fs, viterbi=True)\n",
    "           \n",
    "    #F0_filtered = np.array(confidence_filter(F0, confidence_crepe, threshold))\n",
    "    \n",
    "    F0_estimate_crepe = (time_axis, F0)\n",
    "    #pitch_track_crepe = (time_axis, F0_filtered)\n",
    "    \n",
    "    \n",
    "    hop_length = int(frame_length/4) # 4 by default   \n",
    "    F0, _, confidence_pyin = pyin(bassline, sr=fs, frame_length=frame_length, fmin=31.0, \n",
    "                            fmax=130.0, fill_na=0.0)\n",
    "\n",
    "    #F0_filtered = np.array(confidence_filter(F0, confidence_pyin, threshold))\n",
    "    \n",
    "    time_axis = np.arange(len(F0)) * (hop_length/fs) \n",
    "    \n",
    "    F0_estimate_pyin = (time_axis, F0)\n",
    "    #pitch_track_pyin = (time_axis, F0_filtered) \n",
    "    \n",
    "      \n",
    "    plot_compared_confidences(title, confidence_crepe, confidence_pyin, save=save)\n",
    "    \n",
    "    return [F0_estimate_crepe, F0_estimate_pyin] #, [pitch_track_crepe, pitch_track_pyin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beat_factor = 8 \n",
    "F0_estimates  = yin_crepe(title, bassline, fs, int((beat_length/beat_factor)*fs), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_algorithm_comparison_raw(title, bassline_spectrogram, fs, hop_length, F0_estimates, ['CREPE', 'pYIN'], save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
