{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sys.path.insert(0, '/mnt/d/projects/bassline_transcription')\n",
    "sys.path.insert(0, '/scratch/users/udemir15/ELEC491/bassline_transcription')\n",
    "\n",
    "from representation import NN_output_to_MIDI_file, replace_sustain, encode_midi_sequence\n",
    "from dataset import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = get_directories('../data/directories.json')\n",
    "_, track_dicts, track_titles = read_metadata(directories, 'TechHouse_total_track_dicts.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Analysis Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4420\n"
     ]
    }
   ],
   "source": [
    "with open('../data/metadata/bad_beat_f0_titles.txt', 'r') as infile:\n",
    "    bad_titles = infile.read().split('\\n')\n",
    "    \n",
    "# cross validation results\n",
    "#with open('../data/metadata/removed_tracks.txt', 'r') as infile:\n",
    "#    removed_titles = infile.read().split('\\n')   \n",
    "#bad_titles = bad_titles + removed_titles\n",
    "print(len(bad_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframes from the Transcriber Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=8\n",
    "\n",
    "representation_path = os.path.join('..','data','datasets')\n",
    "df_minor, df_major = create_dataframes(track_dicts, bad_titles, M, directories,  MAX_NOTE=60, MIN_NOTE=24)\n",
    "\n",
    "m_counter = count_keys(df_minor, track_dicts)\n",
    "M_counter = count_keys(df_major, track_dicts)\n",
    "\n",
    "key_pie_charts(m_counter, M_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_minor.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix to a Single Octave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "titles = df.iloc[:,0].tolist()\n",
    "X = df.iloc[:,1:].to_numpy()  \n",
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAX_NOTE = 24\n",
    "X = replace_sustain(X, MAX_NOTE+1)\n",
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NOTE = 37\n",
    "X = replace_sustain(X, MAX_NOTE+1)\n",
    "\n",
    "print(np.unique(X))\n",
    "X[X<13] += 12\n",
    "print(np.unique(X))\n",
    "X[X>=13+12+12] -= 24\n",
    "print(np.unique(X))\n",
    "X[X>=13+12] -= 12\n",
    "print(np.unique(X))\n",
    "X -= 12\n",
    "print(np.unique(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put sustain\n",
    "X = np.stack([encode_midi_sequence(code, sustain_code=13) for code in X], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minor_new = make_dataframe(X, titles)\n",
    "df_minor_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groove Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X!=0] = 1\n",
    "\n",
    "df_minor_new = make_dataframe(X, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'TechHouse_bassline_representations_4521'\n",
    "\n",
    "representation_path = os.path.join('..','data','datasets', 'groove') #'[28, 51]'\n",
    "os.makedirs(representation_path, exist_ok=True)\n",
    "min_title = dataset_name+'_min_M{}.csv'.format(M)\n",
    "min_dir = os.path.join(representation_path, min_title)\n",
    "df_minor_new.to_csv(min_dir, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M=8\n",
    "dataset_name = 'TechHouse_bassline_representations_4020'\n",
    "representation_path = os.path.join('..','data','datasets', '[28, 51]', 'no_sus')\n",
    "\n",
    "os.makedirs(representation_path, exist_ok=True)\n",
    "min_title = dataset_name+'_min_M{}.csv'.format(M)\n",
    "min_dir = os.path.join(representation_path, min_title)\n",
    "df.to_csv(min_dir, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'TechHouse_bassline_representations_4020'\n",
    "\n",
    "representation_path = os.path.join('..','data','datasets', '[28, 51]', 'sus') #'[28, 51]'\n",
    "os.makedirs(representation_path, exist_ok=True)\n",
    "min_title = dataset_name+'_min_M{}.csv'.format(M)\n",
    "min_dir = os.path.join(representation_path, min_title)\n",
    "df_minor.to_csv(min_dir, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset_name = 'TechHouse_bassline_representations'\n",
    "\n",
    "representation_path = os.path.join('..','data','datasets','[28, 51]')\n",
    "\n",
    "for M in [1, 2, 4, 8]:\n",
    "    df_minor, df_major = create_dataframes(track_dicts, bad_titles, M, directories)\n",
    "\n",
    "    min_title = dataset_name+'_min_M{}.csv'.format(M)\n",
    "    min_dir = os.path.join(representation_path, min_title)\n",
    "    df_minor.to_csv(min_dir, index=False, header=False)\n",
    "\n",
    "    maj_title = dataset_name+'_maj_M{}.csv'.format(M)\n",
    "    maj_dir = os.path.join(representation_path, maj_title)\n",
    "    df_major.to_csv(maj_dir, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Track Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = get_directories('../data/directories.json')\n",
    "\n",
    "track_dicts_name = 'traxsource_crawl_0_2500_track_dicts.json'\n",
    "_, track_dicts0, track_titles0 = read_metadata(directories, track_dicts_name)\n",
    "\n",
    "track_dicts_name = 'traxsource_crawl_2500_5000_track_dicts.json'\n",
    "_, track_dicts1, track_titles1 = read_metadata(directories, track_dicts_name)\n",
    "\n",
    "track_dicts_name = 'traxsource_crawl_5000_7500_track_dicts.json'\n",
    "_, track_dicts2, track_titles2 = read_metadata(directories, track_dicts_name)\n",
    "\n",
    "track_dicts_name = 'traxsource_crawl_7500_10000_track_dicts.json'\n",
    "_, track_dicts3, track_titles3 = read_metadata(directories, track_dicts_name)\n",
    "\n",
    "track_dicts_name = 'traxsource_crawl_10000_10898_track_dicts.json'\n",
    "_, track_dicts4, track_titles4 = read_metadata(directories, track_dicts_name)\n",
    "\n",
    "track_dicts_name = 'TechHouse_track_dicts.json'\n",
    "_, track_dicts5, track_titles3 = read_metadata(directories, track_dicts_name)\n",
    "\n",
    "track_dicts = merge_track_dicts(track_dicts0, track_dicts1, track_dicts2, track_dicts3, track_dicts4, track_dicts5)\n",
    "track_titles = list(track_dicts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('../data/metadata/TechHouse_total_track_dicts.json', 'w') as outfile:\n",
    "    json.dump(track_dicts, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## provide non-transposed midi sequences (doesn't funtion now) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note_counter, note_counter_T = count_notes(track_dicts, directories, M)\n",
    "\n",
    "plot_note_occurances(note_counter, note_counter_T, M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
