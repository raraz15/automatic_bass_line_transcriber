{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '/mnt/d/projects/bassline_extraction') \n",
    "\n",
    "import plotting as plot\n",
    "import transcription\n",
    "from utilities import *\n",
    "from signal_processing import *\n",
    "\n",
    "from scipy.io.wavfile import write as wav_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ouz_tracks.txt', 'r') as infile:\n",
    "    track_titles = infile.read().split('\\n')\n",
    "       \n",
    "_,_, bad_examples = next(os.walk('../data/bassline_extraction/beat_grid/bad_examples'))\n",
    "bad_examples = [title.split('.txt')[0] for title in bad_examples]\n",
    "       \n",
    "with open('../data/metadata/scales_frequencies.json','r') as infile:\n",
    "    scales = json.load(infile)\n",
    "\n",
    "with open('../data/metadata/TechHouse_track_dicts.json','r') as infile:\n",
    "    track_dicts = json.load(infile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, len(track_titles), 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in indices:\n",
    "    \n",
    "    try:\n",
    "\n",
    "        title = track_titles[idx] \n",
    "        BPM = float(track_dicts[title]['BPM'])\n",
    "        beat_length = 60/BPM\n",
    "\n",
    "        quarter_beat_positions = get_quarter_beat_positions(get_progression_beat_positions(title))\n",
    "\n",
    "        if title in bad_examples:\n",
    "            continue\n",
    "            with open(os.path.join('../data/bassline_extraction/beat_grid/bad_examples',title+'.txt'), 'r') as infile:\n",
    "                dpqb = float(infile.read())\n",
    "            print(\"Beat grid problematic! dpqb: {:.2f}%\\n{}\".format(dpqb,title))\n",
    "\n",
    "        track_scale = get_track_scale(title, track_dicts, scales)\n",
    "\n",
    "        fs = 44100\n",
    "        chorus, bassline, unprocessed_bassline = load_audio(title) # read the chorus and the bassline\n",
    "        \n",
    "        spectrogram_beat_factor = 8\n",
    "\n",
    "        win_length = int((beat_length/spectrogram_beat_factor)*fs) \n",
    "        n_fft = 4096*8\n",
    "\n",
    "        hop_length = int(win_length/2) \n",
    "        assert win_length < n_fft, 'Window length must be greater than N_fft'\n",
    "\n",
    "        bassline_spectrogram = extract_dB_spectrogram(bassline, n_fft, win_length, hop_length)\n",
    "        \n",
    "        \n",
    "        beat_factor = 8 # for frame size quarter 4, 1/8th 8...\n",
    "\n",
    "        # initial estimate and the filtered version\n",
    "        F0_estimate, pitch_track = transcription.pYIN_F0(bassline,\n",
    "                                                       fs,\n",
    "                                                       int((beat_length/beat_factor)*fs),\n",
    "                                                       threshold=0.05)   \n",
    "        \n",
    "        # Quantize the pitch track\n",
    "        pitch_track_quantized = transcription.adaptive_voiced_region_quantization(pitch_track,\n",
    "                                                                    track_scale,\n",
    "                                                                    quarter_beat_positions, \n",
    "                                                                    length_threshold=beat_factor,\n",
    "                                                                    epsilon=2)\n",
    "\n",
    "        # Extract the Notes for plotting\n",
    "        bassline_notes, unk_bassline_notes = transcription.extract_notes(pitch_track_quantized, track_scale) \n",
    "\n",
    "        # map frequencies to midi\n",
    "        bassline_midi_notes = transcription.get_midi_notes(pitch_track_quantized, 16*beat_factor)\n",
    "        \n",
    "        midi_path = '../data/midi_notes/numpy/{}'.format(title)\n",
    "        np.save('{}.npy'.format(midi_path), bassline_midi_notes)\n",
    "        \n",
    "        wav_write('../data/audio_outputs/choruses/{}.wav'.format(title), fs, chorus)\n",
    "        \n",
    "    except:\n",
    "        print(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
