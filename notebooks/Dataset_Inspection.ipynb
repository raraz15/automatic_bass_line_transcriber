{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '/scratch/users/udemir15/ELEC491/bassline_transcription')\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_params):     \n",
    "    dataset_path, scale_type, M = data_params['dataset_path'], data_params['scale_type'], data_params['M']    \n",
    "    dataset_name = data_params['dataset_name'] +'_{}_M{}.csv'.format(scale_type, M)\n",
    "    dataset_dir = os.path.join(dataset_path, dataset_name)\n",
    "    df = pd.read_csv(dataset_dir, header=None)\n",
    "    titles = df[0].tolist()\n",
    "    X = df[df.columns[1:]].to_numpy()    \n",
    "    return X, titles\n",
    "\n",
    "def append_SOS(X, SOS_token=-1):\n",
    "    X = np.concatenate( (SOS_token*np.ones((X.shape[0],1), dtype=np.int64), X), axis=1)    \n",
    "    return X+1 \n",
    "\n",
    "def count_same_phrases(vector, M, counter):\n",
    "    \n",
    "    vector_re = vector.reshape((4,4, 4*(8//M)))\n",
    "    \n",
    "    for b in range(4):\n",
    "\n",
    "        bars = vector_re[:,b,:] # beat b for all bars\n",
    "\n",
    "        for i in range(4):\n",
    "            for j in range(i+1,4):\n",
    "\n",
    "                B0 = bars[i,:]\n",
    "                B1 = bars[j,:]\n",
    "\n",
    "                if np.array_equal(B0, B1):\n",
    "                    key = '{}{}'.format(i,j)\n",
    "                    counter[b][key] += 1\n",
    "                    \n",
    "    return counter    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = get_directories('../data/directories.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 26\n",
      "Sequence Length: 64\n",
      "Number of data points: 4020\n"
     ]
    }
   ],
   "source": [
    "M = 8\n",
    "\n",
    "data_params = {'dataset_path': '/scratch/users/udemir15/ELEC491/bassline_transcription/data/datasets/[28, 51]',\n",
    "               'dataset_name': 'TechHouse_bassline_representations_4020',\n",
    "               'scale_type': 'min',\n",
    "               'M': M}\n",
    "\n",
    "X, titles = load_data(data_params)\n",
    "#X = append_SOS(X)\n",
    "\n",
    "frequencies = np.unique(X, return_counts=True)\n",
    "\n",
    "K = X.max()+1 # Number of classes, assumes consecutive\n",
    "sequence_length = X.shape[1]\n",
    "\n",
    "print('Number of classes: {}\\nSequence Length: {}'.format(K, sequence_length))\n",
    "print('Number of data points: {}'.format(X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import df_from_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Codebook before correction:\n",
      "[]\n",
      "\n",
      "Codebook after correction:\n",
      "[]\n",
      "\n",
      "Filtered Codes:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "\n",
      "4020/4020 Tracks filtered out because of its notes!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-36206cf757aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_from_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/users/udemir15/ELEC491/bassline_transcription/dataset.py\u001b[0m in \u001b[0;36mdf_from_codes\u001b[0;34m(representations, track_titles, sustain, silence, MAX_NOTE, MIN_NOTE)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n{}/{} Tracks filtered out because of its notes!'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_filtered_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_titles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "df = df_from_codes(X, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('../data/datasets/[28, 51]/TechHouse_bassline_representations_4020_min_M8.csv', header=None, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[1:].to_csv('../data/datasets/[28, 51]/TechHouse_bassline_representations_4020_min_M8.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "titles = df[1][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv('../data/datasets/[28, 51]/TechHouse_bassline_representations_4020_min_M8.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silence_count = frequencies[1][0]\n",
    "note_count = frequencies[1][1:-1].sum()\n",
    "sustain_count = frequencies[1][-1]\n",
    "\n",
    "merged_frequencies = np.array([silence_count, note_count, sustain_count])\n",
    "\n",
    "fig ,ax = plt.subplots(figsize=(10,5))\n",
    "plot_title = 'M={} Merged Code Distribution'.format(M)\n",
    "ax.set_title(plot_title, fontsize=12)\n",
    "ax.bar(['SIL', 'NOTE', 'SUS'], merged_frequencies/merged_frequencies.sum())\n",
    "\n",
    "#plt.savefig(os.path.join(directories['plot']['figures']+'/dataset', 'Merged_Code_Distribution_M{}.jpg'.format(M)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['SIL'] + ['E1', 'F1', 'F#1', 'G1', 'G#1', 'A1', 'A#1', 'B1']+ \\\n",
    "        ['C2', 'C#2', 'D2', 'D#2', 'E2', 'F2', 'F#2', 'G2', 'G#2', 'A2', 'A#2', 'B2']+ \\\n",
    "        ['C3', 'C#3', 'D3','D#3']+ ['SUS']\n",
    "\n",
    "fig ,ax = plt.subplots(figsize=(20,8))\n",
    "plot_title = 'M={} Code Distribution'.format(M)\n",
    "ax.set_title(plot_title, fontsize=15)\n",
    "ax.bar(keys, frequencies[1]/frequencies[1].sum())\n",
    "ax.grid()\n",
    "secax = ax.secondary_xaxis('top')\n",
    "\n",
    "#plt.savefig(os.path.join(directories['plot']['figures']+'/dataset', 'Code_Distribution_M{}.jpg'.format(M)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights = frequencies[1].max() / frequencies[1]\n",
    "weights /= weights.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = {b: {'01': 0, '02': 0, '03': 0, '12': 0, '13': 0, '23': 0} for b in range(4)}\n",
    "for vector in X: #[:, 1:]:\n",
    "    count_same_phrases(vector, M, counter)\n",
    "    \n",
    "for vals in counter.values():\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2,ncols=2, figsize=(12,8))\n",
    "fig.suptitle('Same phrase counts for M={}'.format(M), fontsize=15)\n",
    "\n",
    "ax[0][0].bar(counter[0].keys(), np.array(list(counter[0].values()))/len(X))\n",
    "ax[0][0].set_title('Beat0')\n",
    "ax[0][1].bar(counter[1].keys(), np.array(list(counter[1].values()))/len(X))\n",
    "ax[0][1].set_title('Beat1')\n",
    "ax[1][0].bar(counter[2].keys(), np.array(list(counter[2].values()))/len(X))\n",
    "ax[1][0].set_title('Beat2')\n",
    "ax[1][1].bar(counter[3].keys(), np.array(list(counter[3].values()))/len(X))\n",
    "ax[1][1].set_title('Beat3')\n",
    "\n",
    "#plt.savefig(os.path.join(directories['plot']['figures']+'/dataset', 'Same_Phrase_Counts_M{}.jpg'.format(M)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 56\n",
    "title = titles[idx]\n",
    "print(title)\n",
    "vector = X[idx,1:]\n",
    "print_beat_matrix(vector, M)\n",
    "print('\\n')\n",
    "print_transposed_beat_matrix(vector, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inspect_audio_outputs(title, directories, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dreams of Morjim      | drop mistake\n",
    "# Camilo Do Santos - Bubba Mint (Original Mix)   | note melodic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bassline_transcriber.transcription.representation import encode_midi_array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M = 1\n",
    "sustain_silence=-1\n",
    "sustain_note=-2\n",
    "\n",
    "Y = np.zeros((len(titles), 4*4*(32//M)), dtype=np.int64)\n",
    "for i, title in enumerate(titles):\n",
    "    \n",
    "    midi_array = load_bassline_midi_array(title, directories, M)\n",
    "    new_representation = encode_midi_array_new(midi_array, 8, M, 4, sustain_silence=sustain_silence, sustain_note=sustain_note)\n",
    "    Y[i] = new_representation\n",
    "    \n",
    "    \n",
    "new_frequencies = np.unique(Y, return_counts=True)\n",
    "\n",
    "new_frequencies_merged = (['SUS_NOTE', 'SUS_SIL', 'SIL', 'NOTE'], np.array([new_frequencies[1][0], new_frequencies[1][1],\n",
    "                                                                   new_frequencies[1][2], new_frequencies[1][3:].sum()]))\n",
    "\n",
    "new_frequencies_hard_merged = (['SIL', 'NOTE'], np.array([new_frequencies[1][1:3].sum(),\n",
    "                                                          new_frequencies[1][0]+new_frequencies[1][3:].sum()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,ax = plt.subplots(figsize=(10,5))\n",
    "plot_title = 'M={} Code Distribution with Separate Sustains'.format(M)\n",
    "ax.set_title(plot_title, fontsize=12)\n",
    "ax.bar(new_frequencies_merged[0], new_frequencies_merged[1]/new_frequencies_merged[1].sum())\n",
    "\n",
    "#plt.savefig(os.path.join(directories['plot']['figures']+'/dataset', 'Code_Distribution_Separate_Sustains_M{}.jpg'.format(M)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,ax = plt.subplots(figsize=(10,5))\n",
    "plot_title = 'M={} Code Distribution without sustain'.format(M)\n",
    "ax.set_title(plot_title, fontsize=12)\n",
    "ax.bar(new_frequencies_hard_merged[0], new_frequencies_hard_merged[1]/new_frequencies_hard_merged[1].sum())\n",
    "\n",
    "#plt.savefig(os.path.join(directories['plot']['figures']+'/dataset', 'Code_Distribution_Without_Sustains_M{}.jpg'.format(M)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISTAKES\n",
    "\n",
    "quantization before coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bassline_transcriber.transcription as transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_dicts, track_titles = get_track_dicts(directories, 'TechHouse_total_track_dicts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9851, 512)\n"
     ]
    }
   ],
   "source": [
    "M=1\n",
    "\n",
    "repres = []\n",
    "for title in track_titles:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        key = track_dicts[title]['Key'].split(' ')[0]\n",
    "\n",
    "        quantized_pitch_track = load_quantized_pitch_track(title, directories)[1]\n",
    "        midi_sequence = transcription.frequency_to_midi_sequence(quantized_pitch_track)\n",
    "        midi_sequence = transcription.downsample_midi_number_sequence(midi_sequence, M=M)\n",
    "        representation = transcription.encode_midi_sequence(midi_sequence, key=key)\n",
    "        repres.append(representation)\n",
    "        \n",
    "        export_function(representation, directories['symbolic_representation'][str(M)], title) \n",
    "        \n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        sys.exit()\n",
    "        pass        \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "X = np.stack(repres, axis=0)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "rep = []\n",
    "for row in X:\n",
    "    for idx, val in enumerate(row[:-1]):\n",
    "        \n",
    "        if val == row[idx+1]:\n",
    "            \n",
    "            if val != 100:\n",
    "                counter += 1\n",
    "                #print(row)\n",
    "                #print(idx)\n",
    "                #print(val)\n",
    "                #break\n",
    "                rep.append(val)\n",
    "                print(row[idx-1],val,row[idx+1], row[idx+2],row[idx+3])\n",
    "print(counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
